---
title: Tim Hortons Density
author: Robert M Flight
date: '2013-06-05'
slug: tim-hortons-density
categories: []
tags:
  - R
  - mapping
  - tim-hortons
---



<p>Inspired by this <a href="http://www.ifweassume.com/2012/10/the-united-states-of-starbucks.html">post</a>, I wanted to examine the locations and density of Tim Hortons restaurants in Canada. Using Stats Canada data, each census tract is queried on Foursquare for Tims locations.</p>
<div id="setup" class="section level2">
<h2>Setup</h2>
<pre class="r"><code>options(stringsAsFactors=F)
require(timmysDensity)
require(plyr)
require(maps)
require(ggplot2)
require(geosphere)</code></pre>
</div>
<div id="statistics-canada-census-data" class="section level2">
<h2>Statistics Canada Census Data</h2>
<p>The actual Statistics Canada data at the dissemination block level can be downloaded from <a href="http://www.data.gc.ca/default.asp?lang=En&amp;n=5175A6F0-1&amp;xsl=datacataloguerecord&amp;metaxsl=datacataloguerecord&amp;formid=C87D5FDD-00E6-41A0-B5BA-E8E41B521ED0">here</a>. You will want to download the Excel format, read it, and then save it as either tab-delimited or CSV using a non-standard delimiter, I used a semi-colon (;).</p>
<pre class="r"><code>censusData &lt;- read.table(&quot;../timmysData/2011_92-151_XBB_XLSX.csv&quot;, header=F, sep=&quot;;&quot;, quote=&quot;&quot;)
censusData &lt;- censusData[,1:17]
names(censusData) &lt;- c(&quot;DBuid&quot;, &quot;DBpop2011&quot;, &quot;DBtdwell2011&quot;, &quot;DBurdwell2011&quot;, &quot;DBarea&quot;, &quot;DB_ir2011&quot;, &quot;DAuid&quot;, &quot;DAlamx&quot;, &quot;DAlamy&quot;, &quot;DAlat&quot;,
                       &quot;DAlong&quot;, &quot;PRuid&quot;, &quot;PRname&quot;, &quot;PRename&quot;, &quot;PRfname&quot;, &quot;PReabbr&quot;, &quot;PRfabbr&quot;)
censusData$DBpop2011 &lt;- as.numeric(censusData$DBpop2011)
censusData$DBpop2011[is.na(censusData$DBpop2011)] &lt;- 0

censusData$DBtdwell2011 &lt;- as.numeric(censusData$DBtdwell2011)
censusData$DBtdwell2011[is.na(censusData$DBtdwell2011)] &lt;- 0</code></pre>
<p>From this data we get block level:</p>
<ul>
<li>populations (DBpop2011)</li>
<li>total private dwellings (DBtdwell2011)</li>
<li>privale dwellings occupied by usual residents (DBurdwell2011)</li>
<li>block land area (DBarea)</li>
<li>dissemination area id (DAuid)</li>
<li>representative point x coordinate in Lambert projection (DAlamx)</li>
<li>rep. point y coordinate in Lambert projection (DAlamy)</li>
<li>rep. point latitude (DAlat)</li>
<li>rep. point longitude (DAlong)</li>
</ul>
<p>This should be everything we need to do the investigation we want.</p>
</div>
<div id="dissemination-area-long.-and-lat." class="section level2">
<h2>Dissemination Area Long. and Lat.</h2>
<p>We need to find the unique dissemination areas, and get out their latitudes and longitudes for querying in other databases. Note that the longitude and latitude provided here actually are weighted representative locations based on population. However, given the size of them, I don’t think using them will be a problem for <code>Foursquare</code>. Because areas are what we have location data for, we will summarize everything at the area level, summing the population counts for all the blocks within an area.</p>
<pre class="r"><code>uniqAreas &lt;- unique(censusData$DAuid)

summarizeArea &lt;- function(areaID){
  areaData &lt;- censusData[(censusData$DAuid == areaID),]
  outData &lt;- data.frame(uid=areaID, lamx=areaData[1,&quot;DAlamx&quot;], lamy=areaData[1,&quot;DAlamy&quot;], lat=areaData[1,&quot;DAlat&quot;], long=areaData[1,&quot;DAlong&quot;], pop=sum(areaData[,&quot;DBpop2011&quot;]), dwell=sum(areaData[,&quot;DBtdwell2011&quot;]), prov=areaData[1, &quot;PRename&quot;])
  return(outData)
}
areaData &lt;- adply(uniqAreas, 1, summarizeArea)
.sessionInfo &lt;- sessionInfo()
.timedate &lt;- Sys.time()
write.table(areaData, file=&quot;../timmysData/areaData.txt&quot;, sep=&quot;\t&quot;, row.names=F, col.names=T)
save(areaData, .sessionInfo, .timedate, file=&quot;../timmysData/areaDataFile.RData&quot;, compress=&quot;xz&quot;)</code></pre>
</div>
<div id="run-queries-on-foursquare" class="section level2">
<h2>Run queries on Foursquare</h2>
<div id="load-up-the-data-and-verify-what-we-have." class="section level3">
<h3>Load up the data and verify what we have.</h3>
<pre class="r"><code>load(&quot;../timmysData/areaDataFile.RData&quot;)
head(areaData)</code></pre>
</div>
<div id="generate-queries-and-run" class="section level3">
<h3>Generate queries and run</h3>
<p>For each dissemination area (DA), we are going to use as the location for the query the latitude and longitude of each DA, as well as the search string “tim horton”.</p>
<p>Because Foursquare limits the number of userless requests to <a href="https://developer.foursquare.com/overview/ratelimits">5000 / hr</a>. To make sure we stay under this limit, the <code>runQueries</code> function will only 5000 queries an hour.</p>
<pre class="r"><code>runQueries(areaData, idFile=&quot;../timmysData/clientid.txt&quot;, secretFile=&quot;../timmysData/clientsecret.txt&quot;, outFile=&quot;../timmysData/timmysLocs2.txt&quot;)</code></pre>
</div>
<div id="clean-up-the-results" class="section level3">
<h3>Clean up the results</h3>
<p>Due to the small size of the DAs, we have a lot of duplicate entries. Now lets remove all the duplicate entries.</p>
<pre class="r"><code>cleanUpResults(&quot;../timmysData/timmysLocs2.txt&quot;)</code></pre>
</div>
</div>
<div id="visualize-locations" class="section level2">
<h2>Visualize Locations</h2>
<p>First lets read in the data and make sure that we have Tims locations.</p>
<pre class="r"><code># read in and clean up the data
timsLocs &lt;- scan(file=&quot;../timmysData/timmysLocs2.txt&quot;, what=character(), sep=&quot;\n&quot;)
timsLocs &lt;- strsplit(timsLocs, &quot;:&quot;)

timsName &lt;- sapply(timsLocs, function(x){x[1]})
timsLat &lt;- sapply(timsLocs, function(x){x[2]})
timsLong &lt;- sapply(timsLocs, function(x){x[3]})

locData &lt;- data.frame(description=timsName, lat=as.numeric(timsLat), long=as.numeric(timsLong))
hasNA &lt;- is.na(locData[,&quot;lat&quot;]) | is.na(locData[,&quot;long&quot;])
locData &lt;- locData[!(hasNA),]

timsStr &lt;- c(&quot;tim hortons&quot;, &quot;tim horton&#39;s&quot;)

hasTims &lt;- (grepl(timsStr[1], locData$description, ignore.case=T)) | (grepl(timsStr[2], locData$description, ignore.case=T))

locData &lt;- locData[hasTims,]
timsLocs &lt;- locData
rm(timsName, timsLat, timsLong, hasNA, locData, hasTims, timsStr)
.timedate &lt;- Sys.time()
.sessionInfo &lt;- sessionInfo()
save(timsLocs, .timedate, .sessionInfo, file=&quot;../timmysData/timsLocs.RData&quot;, compress=&quot;xz&quot;)</code></pre>
<div id="put-them-on-a-map" class="section level3">
<h3>Put them on a map</h3>
<pre class="r"><code>data(timsLocs)
data(areaDataFile)
canada &lt;- map_data(&quot;world&quot;, &quot;canada&quot;)

p &lt;- ggplot(legend=FALSE) +
  geom_polygon( data=canada, aes(x=long, y=lat,group=group)) +
  theme(panel.background = element_blank()) +
  theme(panel.grid.major = element_blank()) +
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text.x = element_blank(),axis.text.y = element_blank()) +
  theme(axis.ticks = element_blank()) +
  xlab(&quot;&quot;) + ylab(&quot;&quot;)

sp &lt;- timsLocs[1, c(&quot;lat&quot;, &quot;long&quot;)]

p2 &lt;- p + geom_point(data=timsLocs[,c(&quot;lat&quot;, &quot;long&quot;)], aes(x=long, y=lat), colour=&quot;green&quot;, size=1, alpha=0.5)

print(p2)</code></pre>
<p><img src="/post/2013-06-05-tim-hortons-density_files/figure-html/mapIt-1.png" width="672" /></p>
</div>
<div id="how-far" class="section level3">
<h3>How far??</h3>
<p>And now lets also calculate the minimum distance of a given DA from Timmys locations.</p>
<pre class="r"><code>queryLocs &lt;- matrix(c(timsLocs$long, timsLocs$lat), nrow=nrow(timsLocs), ncol=2, byrow=F) # these are the tims locations
distLocs &lt;- matrix(c(areaData$long, areaData$lat), nrow=nrow(areaData), ncol=2, byrow=F) # the census centers
allDists &lt;- apply(queryLocs, 1, function(x){
  min(distHaversine(x, distLocs)) # only need the minimum value to determine 
})</code></pre>
<p>From the <code>allDists</code> variable above, we can determine that the maximum distance any census dissemination area (DA) is from a Tim Hortons is 51.5 km (31.9815 miles). This is based on distances calculated “as the crow flies”, but still, that is pretty close. Assuming roads, the furthest a Canadian should have to travel is less than an hour to get their Timmys fix.</p>
<pre class="r"><code>totPopulation &lt;- sum(areaData$pop, na.rm=T)
lessDist &lt;- seq(50, 51.6 * 1000, 50) # distances are in meters, so multiply by 1000 to get reasonable km

percPop &lt;- sapply(lessDist, function(inDist){
  isLess &lt;- allDists &lt; inDist
  sum(areaData$pop[isLess], na.rm=T) / totPopulation * 100
})

plotDistPerc &lt;- data.frame(distance=lessDist, population=percPop, logDist=log10(lessDist))
ggplot(plotDistPerc, aes(x=logDist, y=population)) + geom_point() + xlab(&quot;Log10 Distance&quot;) + ylab(&quot;% Population&quot;)</code></pre>
<p><img src="/post/2013-06-05-tim-hortons-density_files/figure-html/percPopulation-1.png" width="672" /></p>
<p>What gets really interesting, is how much of the population lives within a given distance of a Timmys. By summing up the percentage of the population within given distances. The plot above shows that 50% of the population is within 316.227766 <strong>meters</strong> of a Tim Hortons location.</p>
<p>I guess Canadians really do like their Tim Hortons Coffee (and donuts!).</p>
</div>
</div>
<div id="replication" class="section level2">
<h2>Replication</h2>
<p>All of the necessary processed data and code is available in the <code>R</code> package <a href="https://github.com/rmflight/timmysDensity"><code>timmysDensity</code></a>. You can install it using <code>devtools</code>. The original data files are linked in the relevant sections above.</p>
<pre class="r"><code>library(devtools)
install_github(&#39;timmysDensity&#39;, &#39;rmflight&#39;)</code></pre>
<div id="caveats" class="section level3">
<h3>Caveats</h3>
<p>I originally did this work based on a different set of data, that I have not been able to locate the original source for. I have not compared these results to that data to verify their accuracy. When I do so, I will update the package, vignette and blog post.</p>
</div>
</div>
<div id="posted" class="section level2">
<h2>Posted</h2>
<p>This work exists as the vignette of <a href="https://github.com/rmflight/timmysDensity"><code>timmysDensity</code></a>, on my <a href="https://rmflight.github.io/posts/2013/06/timmysDensity.html">web-blog</a>, and independently as the front page for the <a href="http://rmflight.github.io/timmysDensity">GitHub repo</a>.</p>
</div>
<div id="disclaimer" class="section level2">
<h2>Disclaimer</h2>
<p>Tim Hortons was not involved in the creation or preparation of this work. I am not regularly updating the location information obtained from Foursquare, it is only valid for May 31, 2013. All code used in preparing these results was written by me, except in the case where code from other <code>R</code> packages was used. All opinions and conclusions are my own, and do not reflect the views of anyone else or any institution I may be associated with.</p>
</div>
<div id="other-information-when-this-vignette-was-generated" class="section level2">
<h2>Other information when this vignette was generated</h2>
<div id="session-info" class="section level3">
<h3>Session Info</h3>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Ubuntu 18.04.3 LTS
## 
## Matrix products: default
## BLAS: /software/R-351/lib/R/lib/libRblas.so
## LAPACK: /software/R-351/lib/R/lib/libRlapack.so
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] geosphere_1.5-7     ggplot2_3.1.1       maps_3.3.0         
## [4] plyr_1.8.4          timmysDensity_0.0.6
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.2       compiler_3.5.1   pillar_1.4.2     bitops_1.0-6    
##  [5] tools_3.5.1      digest_0.6.20    lattice_0.20-38  lubridate_1.7.4 
##  [9] evaluate_0.14    tibble_2.1.3     gtable_0.3.0     pkgconfig_2.0.2 
## [13] rlang_0.4.0.9002 yaml_2.2.0       blogdown_0.10    xfun_0.8        
## [17] withr_2.1.2      stringr_1.4.0    dplyr_0.8.3      knitr_1.24      
## [21] grid_3.5.1       tidyselect_0.2.5 glue_1.3.1       R6_2.4.0        
## [25] rmarkdown_1.15   bookdown_0.9     RJSONIO_1.3-1.1  sp_1.3-1        
## [29] purrr_0.3.2      magrittr_1.5     scales_1.0.0     htmltools_0.3.6 
## [33] assertthat_0.2.1 colorspace_1.4-1 labeling_0.3     stringi_1.4.3   
## [37] RCurl_1.95-4.12  lazyeval_0.2.2   munsell_0.5.0    crayon_1.3.4    
## [41] Cairo_1.5-9</code></pre>
</div>
<div id="time-and-date" class="section level3">
<h3>Time and Date</h3>
<pre class="r"><code>Sys.time()</code></pre>
<pre><code>## [1] &quot;2019-10-16 10:12:34 EDT&quot;</code></pre>
</div>
</div>
